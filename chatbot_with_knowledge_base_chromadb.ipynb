{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a chatbot with its own knowledge base using ChromaDB with Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I'll load documents from a directory and create a vector store to build the knowledge base for a chatbot. I'll use the [ChromaDB](https://python.langchain.com/docs/integrations/vectorstores/chroma)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to load documents from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from typing import Union\n",
    "\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#list of allowed file types\n",
    "ALLOWED_FILES = ['pdf', 'txt', 'docx', 'xml', 'html', 'md', 'json']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full documentation about directory loadder or file loaders can be found in the [langchain documentation](https://python.langchain.com/docs/integrations/document_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#function to load a single file, HTML\n",
    "def load_html(file_path: str):\n",
    "    '''\n",
    "        function to load html files form the dir\n",
    "\n",
    "        params:\n",
    "            file_path: str: path of the file with its name\n",
    "\n",
    "        returns:\n",
    "            Doc object\n",
    "    '''\n",
    "\n",
    "    #import HTML loader\n",
    "    from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "    #prepare loader\n",
    "    print(f\"Loading HTML file '{file_path}'...\")\n",
    "    loader = UnstructuredHTMLLoader(file_path)\n",
    "    #load document\n",
    "    doc = loader.load()\n",
    "    print(f\"Loaded HTML file '{doc.metadata['filename']}'\")\n",
    "    #return document\n",
    "    return doc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load a directory\n",
    "def load_directory(path:str, file_types: Union[str, list]):\n",
    "    '''\n",
    "        function to load documents from a directory\n",
    "    \n",
    "        params:\n",
    "            path: str: path pof the dir to load documents from\n",
    "            file_types: (str or list of strings): file formats to load e.g. .pdf, .docx etc\n",
    "\n",
    "        returns:\n",
    "            Docloader object\n",
    "\n",
    "    '''\n",
    "\n",
    "    # convert file_types to a list if it is a string\n",
    "    if isinstance(file_types, str):\n",
    "        file_types = [file_types]\n",
    "\n",
    "    # if file_types is not in the allowed files list, raise an error\n",
    "    for fl in file_types:\n",
    "        if fl not in ALLOWED_FILES:\n",
    "            raise ValueError(f\"File type {fl} is not allowed. Allowed file types are: {ALLOWED_FILES}\")\n",
    "\n",
    "    #list to store all loader objects\n",
    "    docs_list = []\n",
    "    #for each file type in the file_types parameter\n",
    "    for fl in file_types:\n",
    "        #load docs\n",
    "        print(f\"Loading {fl} files...\")\n",
    "        try:\n",
    "            if fl != 'html':\n",
    "                loader = DirectoryLoader(\n",
    "                            path,\n",
    "                            glob=f\"**/*.{fl}\",\n",
    "                            show_progress=True,\n",
    "                            use_multithreading=True,\n",
    "                            recursive=True\n",
    "                        )\n",
    "                docs = loader.load()\n",
    "                print(f\"Loaded {len(docs)} {fl} files\")\n",
    "                #add into the list of loader objects\n",
    "                docs_list+=docs\n",
    "            else:\n",
    "                html_list = glob.glob(os.path.join(path, '*.html'))\n",
    "                docs = []\n",
    "                for ht in html_list:\n",
    "                    #add into the list of loader objects\n",
    "                    docs_list+=load_html(ht)\n",
    "                    # docs.append(load_html(ht))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {fl} files: {e}\")\n",
    "    \n",
    "    return docs_list\n",
    "    #return the final loaded list of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A processor function to process the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain import document_loaders\n",
    "\n",
    "\n",
    "def process_docs(docs: document_loaders):\n",
    "    '''\n",
    "        function to split text into sentences and words\n",
    "\n",
    "        parameters:\n",
    "            docs: list of document objects\n",
    "\n",
    "        returns:\n",
    "            texts: list of text objects\n",
    "    '''\n",
    "\n",
    "    #load text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter()\n",
    "    #split documents\n",
    "    print('Splitting documents...')\n",
    "    texts = text_splitter.split_documents(docs)\n",
    "\n",
    "    return texts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving documents to a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  setup sqlite3 for linux based OS, for windows it's not needed, comment these lines for windows\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Obtaining dependency information for chromadb from https://files.pythonhosted.org/packages/27/58/7bf23f206b8ad9507295067f08b7cc42d4a91d9877301abf0807df8fbe67/chromadb-0.4.13-py3-none-any.whl.metadata\n",
      "  Downloading chromadb-0.4.13-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: requests>=2.28 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from chromadb) (1.10.13)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from chromadb) (0.103.2)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from chromadb) (0.23.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from chromadb) (3.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from chromadb) (4.8.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from chromadb) (3.3.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from chromadb) (1.16.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from chromadb) (0.14.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from chromadb) (4.66.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from chromadb) (6.1.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from chromadb) (4.0.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from chromadb) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from chromadb) (1.26.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from fastapi>=0.95.2->chromadb) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from fastapi>=0.95.2->chromadb) (0.27.0)\n",
      "Requirement already satisfied: coloredlogs in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: packaging in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
      "Requirement already satisfied: protobuf in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (4.24.4)\n",
      "Requirement already satisfied: sympy in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: six>=1.5 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>2.1 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: certifi in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from requests>=2.28->chromadb) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from requests>=2.28->chromadb) (2.0.5)\n",
      "Requirement already satisfied: huggingface_hub<0.17,>=0.16.4 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from tokenizers>=0.13.2->chromadb) (0.16.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.20.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from importlib-resources->chromadb) (3.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.1.3)\n",
      "Requirement already satisfied: filelock in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.12.4)\n",
      "Requirement already satisfied: fsspec in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from huggingface_hub<0.17,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.9.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/irfan/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Using cached chromadb-0.4.13-py3-none-any.whl (437 kB)\n",
      "Installing collected packages: chromadb\n",
      "Successfully installed chromadb-0.4.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Chroma is running in http-only client mode, and can only be run with 'chromadb.api.fastapi.FastAPI' as the chroma_api_impl.             see https://docs.trychroma.com/usage-guide?lang=py#using-the-python-http-only-client for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# # get chroma db max batch size\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mchromadb\u001b[39;00m \u001b[39mimport\u001b[39;00m Client\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m chromadb_client \u001b[39m=\u001b[39m Client()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m chroma_batch_size \u001b[39m=\u001b[39m chromadb_client\u001b[39m.\u001b[39mmax_batch_size\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mChroma DB max batch size: \u001b[39m\u001b[39m{\u001b[39;00mchroma_batch_size\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages/chromadb/__init__.py:140\u001b[0m, in \u001b[0;36mClient\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mClient\u001b[39m(settings: Settings \u001b[39m=\u001b[39m __settings) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m API:\n\u001b[1;32m    138\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a running chroma.API instance\"\"\"\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     system \u001b[39m=\u001b[39m System(settings)\n\u001b[1;32m    142\u001b[0m     telemetry_client \u001b[39m=\u001b[39m system\u001b[39m.\u001b[39minstance(Telemetry)\n\u001b[1;32m    143\u001b[0m     api \u001b[39m=\u001b[39m system\u001b[39m.\u001b[39minstance(API)\n",
      "File \u001b[0;32m~/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages/chromadb/config.py:237\u001b[0m, in \u001b[0;36mSystem.__init__\u001b[0;34m(self, settings)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m is_thin_client:\n\u001b[1;32m    235\u001b[0m     \u001b[39m# The thin client is a system with only the API component\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m settings[\u001b[39m\"\u001b[39m\u001b[39mchroma_api_impl\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mchromadb.api.fastapi.FastAPI\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 237\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    238\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mChroma is running in http-only client mode, and can only be run with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mchromadb.api.fastapi.FastAPI\u001b[39m\u001b[39m'\u001b[39m\u001b[39m as the chroma_api_impl. \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39m    see https://docs.trychroma.com/usage-guide?lang=py#using-the-python-http-only-client for more information.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m         )\n\u001b[1;32m    241\u001b[0m \u001b[39m# Validate settings don't contain any legacy config values\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m _legacy_config_keys:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Chroma is running in http-only client mode, and can only be run with 'chromadb.api.fastapi.FastAPI' as the chroma_api_impl.             see https://docs.trychroma.com/usage-guide?lang=py#using-the-python-http-only-client for more information."
     ]
    }
   ],
   "source": [
    "# # get chroma db max batch size\n",
    "from chromadb import Client\n",
    "chromadb_client = Client()\n",
    "chroma_batch_size = chromadb_client.max_batch_size\n",
    "print(f\"Chroma DB max batch size: {chroma_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain import embeddings, text_splitter\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import time\n",
    "\n",
    "chroma_batch_size = 166\n",
    "\n",
    "def store_db(texts: text_splitter, embeddings: embeddings, persist_directory: Optional[str], persist: Optional[bool]):\n",
    "    '''\n",
    "        function to store the database\n",
    "\n",
    "        parameters:\n",
    "            texts: list of text objects\n",
    "            embeddings: embeddings to apply\n",
    "            persist_directory: directory to save the database\n",
    "            persist: whether to persist the database or not\n",
    "\n",
    "        returns:\n",
    "            vector_store: vector store object\n",
    "    '''\n",
    "\n",
    "    vector_db = None\n",
    "    def store(text):\n",
    "\n",
    "        #if persist is true and persist_directory is not None or persist is false and persist_directory is not None\n",
    "        if (persist and persist_directory is not None) or (not persist and persist_directory is not None):\n",
    "            #store texts into directory\n",
    "            print(f\"Storing database in directory '{persist_directory}'...\")\n",
    "\n",
    "            vector_db = vector_store.from_documents(\n",
    "                                            documents=text, \n",
    "                                            embedding=embeddings,\n",
    "                                            persist_directory=persist_directory\n",
    "                                        )\n",
    "            \n",
    "        #else if persist is true and persist_directory is None\n",
    "        elif persist and persist_directory is None:\n",
    "            #store texts into memory\n",
    "            raise Exception(\"Persist directory must be specified to persist the database\")\n",
    "        #else if persist is false and persist_directory is None\n",
    "        elif not persist and persist_directory is None:\n",
    "            print(\"Storing database in memory...\")\n",
    "            #store texts into memory\n",
    "            vector_db = vector_store.from_documents(documents=texts, \n",
    "                                    embedding=embeddings)\n",
    "            \n",
    "        return vector_db\n",
    "\n",
    "\n",
    "    print('total docs to be stored: ', len(texts))\n",
    "\n",
    "    #load vector store\n",
    "    vector_store = Chroma()\n",
    "\n",
    "    #if the number of texts is greater than the chroma db max batch size\n",
    "    if len(texts) > chroma_batch_size:\n",
    "        #split texts into batches\n",
    "        texts = [texts[i:i+chroma_batch_size] for i in range(0, len(texts), chroma_batch_size)]\n",
    "        print('total batches: ', len(texts))\n",
    "\n",
    "        #for each batch in texts\n",
    "        # store batch\n",
    "        # keep count of the number of batches\n",
    "        # after every 3rd batch sleep for 1.5 minutes\n",
    "        # this is to prevent the chroma db from crashing\n",
    "        for i, batch in enumerate(texts):\n",
    "            #store batch\n",
    "            vector_db = store(batch)\n",
    "            time.sleep(1.5)\n",
    "            if i % 3 == 0:\n",
    "                print('sleeping for 90 seconds...')\n",
    "                time.sleep(90)\n",
    "    else:\n",
    "        #store texts\n",
    "        vector_db = store(texts)\n",
    "\n",
    "    \n",
    "    if vector_db is None:\n",
    "        raise Exception('Database could not be stored')\n",
    "    \n",
    "    return vector_db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The function to ingest documents from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import some accessory modules from langchain\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "import argparse\n",
    "from typing import Union, Optional\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the .env file\n",
    "load_dotenv(find_dotenv())\n",
    "open_ai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ingest(\n",
    "            path: str,\n",
    "            file_types: str = 'pdf, docx, html, txt, xml, md, json',\n",
    "            embeddings=OpenAIEmbeddings(\n",
    "                                        openai_api_key=open_ai_api_key,\n",
    "                                        show_progress_bar=True\n",
    "                                    ),\n",
    "            persist_directory: Optional[str]='db',\n",
    "            persist: Optional[bool]=True\n",
    "        ):\n",
    "    '''\n",
    "        function to ingest documents\n",
    "\n",
    "        parameters:\n",
    "            path: str: path of the dir to load documents from\n",
    "            file_types: str: file formats to load e.g. 'pdf, docx, md, txt'  etc\n",
    "            embeddings: embeddings to apply\n",
    "            persist_directory: directory to save the database\n",
    "            persist: whether to persist the database or not\n",
    "\n",
    "        returns:\n",
    "            vector_store: vector store object\n",
    "    '''\n",
    "\n",
    "    file_types = file_types.split(',')\n",
    "\n",
    "    file_types = [fl.strip() for fl in file_types if fl.strip() != '']\n",
    "\n",
    "    # print(file_types)\n",
    "    print('File types: ', file_types)\n",
    "\n",
    "    print('Loading documents from directory...', path)\n",
    "\n",
    "    #load documents\n",
    "    docs = load_directory(path, file_types)\n",
    "    print(f'Loaded {len(docs)} documents from directory: ', path, ' Successfully')\n",
    "    #process documents\n",
    "    texts = process_docs(docs)\n",
    "    #store database\n",
    "    vector_store = store_db(texts, embeddings, persist_directory, persist)\n",
    "\n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's test the directory ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The db_files dir contains a book related to bioinformatics and an HTML file of bioinformatics wikipedia. Let's ingest that and then we'll query the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File types:  ['html', 'txt', 'pdf', 'docx', 'md', 'xml', 'json']\n",
      "Loading documents from directory... db_files\n",
      "Loading html files...\n",
      "Loading HTML file 'db_files/Bioinformatics - Wikipedia.html'...\n",
      "Error loading html files: 'list' object has no attribute 'metadata'\n",
      "Loading txt files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 txt files\n",
      "Loading pdf files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 78.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 pdf files\n",
      "Loading docx files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 docx files\n",
      "Loading md files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 md files\n",
      "Loading xml files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 xml files\n",
      "Loading json files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 json files\n",
      "Loaded 0 documents from directory:  db_files  Successfully\n",
      "Splitting documents...\n",
      "total docs to be stored:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import chromadb python package. Please install it with `pip install chromadb`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages/langchain/vectorstores/chroma.py:80\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chromadb'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m store \u001b[39m=\u001b[39m ingest(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                 \u001b[39m'\u001b[39;49m\u001b[39mdb_files\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                 file_types\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhtml, txt, pdf, docx, md, xml, json\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                 embeddings\u001b[39m=\u001b[39;49mOpenAIEmbeddings(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                         openai_api_key\u001b[39m=\u001b[39;49mopen_ai_api_key,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                         show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                     ),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                 persist_directory\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdb\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                 persist\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m             )\n",
      "\u001b[1;32m/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb Cell 21\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m texts \u001b[39m=\u001b[39m process_docs(docs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m#store database\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m vector_store \u001b[39m=\u001b[39m store_db(texts, embeddings, persist_directory, persist)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mreturn\u001b[39;00m vector_store\n",
      "\u001b[1;32m/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb Cell 21\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtotal docs to be stored: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(texts))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m#load vector store\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m vector_store \u001b[39m=\u001b[39m Chroma()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m#if the number of texts is greater than the chroma db max batch size\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(texts) \u001b[39m>\u001b[39m chroma_batch_size:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X55sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     \u001b[39m#split texts into batches\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages/langchain/vectorstores/chroma.py:83\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     84\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import chromadb python package. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease install it with `pip install chromadb`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m     )\n\u001b[1;32m     88\u001b[0m \u001b[39mif\u001b[39;00m client \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client_settings \u001b[39m=\u001b[39m client_settings\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import chromadb python package. Please install it with `pip install chromadb`."
     ]
    }
   ],
   "source": [
    "store = ingest(\n",
    "                'db_files',\n",
    "                file_types='html, txt, pdf, docx, md, xml, json',\n",
    "                embeddings=OpenAIEmbeddings(\n",
    "                                        openai_api_key=open_ai_api_key,\n",
    "                                        show_progress_bar=True\n",
    "                                    ),\n",
    "                persist_directory='db',\n",
    "                persist=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can use the following method in a .py script**\n",
    "\n",
    "It can also be run with in scheduled to automate directory loading and ingestion of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def main():\n",
    "#     parser = argparse.ArgumentParser(description='Ingest documents into a vector store')\n",
    "#     parser.add_argument('path', type=str, help='path of the dir to load documents from')\n",
    "#     parser.add_argument('file_types', type=str, help='file formats to load e.g. .pdf, .docx etc')\n",
    "#     parser.add_argument('persist_directory', type=str, help='directory to save the database')\n",
    "#     parser.add_argument('persist', type=bool, help='whether to persist the database or not')\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     #embeddings\n",
    "#     embeddings = OpenAIEmbeddings(openai_api_key=open_ai_api_key )\n",
    "\n",
    "#     #ingest documents\n",
    "#     store = ingest(args.path, args.file_types.strip(), embeddings, args.persist_directory, args.persist)\n",
    "\n",
    "#     print('Database stored successfully', store.get()['metadatas'][0]['source'])\n",
    "\n",
    "#     print('Exiting...')\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
