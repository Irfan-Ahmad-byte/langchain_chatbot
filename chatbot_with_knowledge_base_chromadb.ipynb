{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a chatbot with its own knowledge base using ChromaDB with Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I'll load documents from a directory and create a vector store to build the knowledge base for a chatbot. I'll use the [ChromaDB](https://python.langchain.com/docs/integrations/vectorstores/chroma)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to load documents from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from typing import Union\n",
    "\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#list of allowed file types\n",
    "ALLOWED_FILES = ['pdf', 'txt', 'docx', 'xml', 'html', 'md', 'json']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full documentation about directory loadder or file loaders can be found in the [langchain documentation](https://python.langchain.com/docs/integrations/document_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#function to load a single file, HTML\n",
    "def load_html(file_path: str):\n",
    "    '''\n",
    "        function to load html files form the dir\n",
    "\n",
    "        params:\n",
    "            file_path: str: path of the file with its name\n",
    "\n",
    "        returns:\n",
    "            Doc object\n",
    "    '''\n",
    "\n",
    "    #import HTML loader\n",
    "    from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "    #prepare loader\n",
    "    print(f\"Loading HTML file '{file_path}'...\")\n",
    "    loader = UnstructuredHTMLLoader(file_path)\n",
    "    #load document\n",
    "    doc = loader.load()\n",
    "    print(f\"Loaded HTML file '{doc.metadata['filename']}'\")\n",
    "    #return document\n",
    "    return doc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load a directory\n",
    "def load_directory(path:str, file_types: Union[str, list]):\n",
    "    '''\n",
    "        function to load documents from a directory\n",
    "    \n",
    "        params:\n",
    "            path: str: path pof the dir to load documents from\n",
    "            file_types: (str or list of strings): file formats to load e.g. .pdf, .docx etc\n",
    "\n",
    "        returns:\n",
    "            Docloader object\n",
    "\n",
    "    '''\n",
    "\n",
    "    # convert file_types to a list if it is a string\n",
    "    if isinstance(file_types, str):\n",
    "        file_types = [file_types]\n",
    "\n",
    "    # if file_types is not in the allowed files list, raise an error\n",
    "    for fl in file_types:\n",
    "        if fl not in ALLOWED_FILES:\n",
    "            raise ValueError(f\"File type {fl} is not allowed. Allowed file types are: {ALLOWED_FILES}\")\n",
    "\n",
    "    #list to store all loader objects\n",
    "    docs_list = []\n",
    "    #for each file type in the file_types parameter\n",
    "    for fl in file_types:\n",
    "        #load docs\n",
    "        print(f\"Loading {fl} files...\")\n",
    "        try:\n",
    "            if fl != 'html':\n",
    "                loader = DirectoryLoader(\n",
    "                            path,\n",
    "                            glob=f\"**/*.{fl}\",\n",
    "                            show_progress=True,\n",
    "                            use_multithreading=True,\n",
    "                            recursive=True\n",
    "                        )\n",
    "                docs = loader.load()\n",
    "                print(f\"Loaded {len(docs)} {fl} files\")\n",
    "                #add into the list of loader objects\n",
    "                docs_list+=docs\n",
    "            else:\n",
    "                html_list = glob.glob(os.path.join(path, '*.html'))\n",
    "                docs = []\n",
    "                for ht in html_list:\n",
    "                    #add into the list of loader objects\n",
    "                    docs_list+=load_html(ht)\n",
    "                    # docs.append(load_html(ht))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {fl} files: {e}\")\n",
    "    \n",
    "    return docs_list\n",
    "    #return the final loaded list of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A processor function to process the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain import document_loaders\n",
    "\n",
    "\n",
    "def process_docs(docs: document_loaders):\n",
    "    '''\n",
    "        function to split text into sentences and words\n",
    "\n",
    "        parameters:\n",
    "            docs: list of document objects\n",
    "\n",
    "        returns:\n",
    "            texts: list of text objects\n",
    "    '''\n",
    "\n",
    "    #load text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter()\n",
    "    #split documents\n",
    "    print('Splitting documents...')\n",
    "    texts = text_splitter.split_documents(docs)\n",
    "\n",
    "    return texts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving documents to a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  setup sqlite3 for linux based OS, for windows it's not needed, comment these lines for windows\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma DB max batch size: 41666\n"
     ]
    }
   ],
   "source": [
    "# # get chroma db max batch size\n",
    "from chromadb import Client\n",
    "chromadb_client = Client()\n",
    "chroma_batch_size = chromadb_client.max_batch_size\n",
    "print(f\"Chroma DB max batch size: {chroma_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain import embeddings, text_splitter\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import time\n",
    "\n",
    "def store_db(texts: text_splitter, embeddings: embeddings, persist_directory: Optional[str], persist: Optional[bool]):\n",
    "    '''\n",
    "        function to store the database\n",
    "\n",
    "        parameters:\n",
    "            texts: list of text objects\n",
    "            embeddings: embeddings to apply\n",
    "            persist_directory: directory to save the database\n",
    "            persist: whether to persist the database or not\n",
    "\n",
    "        returns:\n",
    "            vector_store: vector store object\n",
    "    '''\n",
    "\n",
    "    vector_db = None\n",
    "    def store(text):\n",
    "\n",
    "        #if persist is true and persist_directory is not None or persist is false and persist_directory is not None\n",
    "        if (persist and persist_directory is not None) or (not persist and persist_directory is not None):\n",
    "            #store texts into directory\n",
    "            print(f\"Storing database in directory '{persist_directory}'...\")\n",
    "\n",
    "            vector_db = vector_store.from_documents(\n",
    "                                            documents=text, \n",
    "                                            embedding=embeddings,\n",
    "                                            persist_directory=persist_directory\n",
    "                                        )\n",
    "            \n",
    "        #else if persist is true and persist_directory is None\n",
    "        elif persist and persist_directory is None:\n",
    "            #store texts into memory\n",
    "            raise Exception(\"Persist directory must be specified to persist the database\")\n",
    "        #else if persist is false and persist_directory is None\n",
    "        elif not persist and persist_directory is None:\n",
    "            print(\"Storing database in memory...\")\n",
    "            #store texts into memory\n",
    "            vector_db = vector_store.from_documents(documents=texts, \n",
    "                                    embedding=embeddings)\n",
    "            \n",
    "        return vector_db\n",
    "\n",
    "\n",
    "    print('total docs to be stored: ', len(texts))\n",
    "\n",
    "    #load vector store\n",
    "    vector_store = Chroma()\n",
    "\n",
    "    #if the number of texts is greater than the chroma db max batch size\n",
    "    if len(texts) > chroma_batch_size:\n",
    "        #split texts into batches\n",
    "        texts = [texts[i:i+chroma_batch_size] for i in range(0, len(texts), chroma_batch_size)]\n",
    "        print('total batches: ', len(texts))\n",
    "\n",
    "        #for each batch in texts\n",
    "        # store batch\n",
    "        # keep count of the number of batches\n",
    "        # after every 3rd batch sleep for 1.5 minutes\n",
    "        # this is to prevent the chroma db from crashing\n",
    "        for i, batch in enumerate(texts):\n",
    "            #store batch\n",
    "            vector_db = store(batch)\n",
    "            time.sleep(1.5)\n",
    "            if i % 3 == 0:\n",
    "                print('sleeping for 90 seconds...')\n",
    "                time.sleep(90)\n",
    "    else:\n",
    "        #store texts\n",
    "        vector_db = store(texts)\n",
    "\n",
    "    \n",
    "    if vector_db is None:\n",
    "        raise Exception('Database could not be stored')\n",
    "    \n",
    "    return vector_db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The function to ingest documents from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import some accessory modules from langchain\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "import argparse\n",
    "from typing import Union, Optional\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the .env file\n",
    "load_dotenv(find_dotenv())\n",
    "open_ai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ingest(\n",
    "            path: str,\n",
    "            file_types: str = 'pdf, docx, html, txt, xml, md, json',\n",
    "            embeddings=OpenAIEmbeddings(\n",
    "                                        openai_api_key=open_ai_api_key,\n",
    "                                        show_progress_bar=True\n",
    "                                    ),\n",
    "            persist_directory: Optional[str]='db',\n",
    "            persist: Optional[bool]=True\n",
    "        ):\n",
    "    '''\n",
    "        function to ingest documents\n",
    "\n",
    "        parameters:\n",
    "            path: str: path of the dir to load documents from\n",
    "            file_types: str: file formats to load e.g. 'pdf, docx, md, txt'  etc\n",
    "            embeddings: embeddings to apply\n",
    "            persist_directory: directory to save the database\n",
    "            persist: whether to persist the database or not\n",
    "\n",
    "        returns:\n",
    "            vector_store: vector store object\n",
    "    '''\n",
    "\n",
    "    file_types = file_types.split(',')\n",
    "\n",
    "    file_types = [fl.strip() for fl in file_types if fl.strip() != '']\n",
    "\n",
    "    # print(file_types)\n",
    "    print('File types: ', file_types)\n",
    "\n",
    "    print('Loading documents from directory...', path)\n",
    "\n",
    "    #load documents\n",
    "    docs = load_directory(path, file_types)\n",
    "    print(f'Loaded {len(docs)} documents from directory: ', path, ' Successfully')\n",
    "    #process documents\n",
    "    texts = process_docs(docs)\n",
    "    #store database\n",
    "    vector_store = store_db(texts, embeddings, persist_directory, persist)\n",
    "\n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's test the directory ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The db_files dir contains a book related to bioinformatics and an HTML file of bioinformatics wikipedia. Let's ingest that and then we'll query the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File types:  ['html', 'txt', 'pdf', 'docx', 'md', 'xml', 'json']\n",
      "Loading documents from directory... db_files\n",
      "Loading html files...\n",
      "Loading HTML file 'db_files/Bioinformatics - Wikipedia.html'...\n",
      "Error loading html files: 'list' object has no attribute 'metadata'\n",
      "Loading txt files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 txt files\n",
      "Loading pdf files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 119.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 pdf files\n",
      "Loading docx files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 docx files\n",
      "Loading md files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 md files\n",
      "Loading xml files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 xml files\n",
      "Loading json files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 json files\n",
      "Loaded 0 documents from directory:  db_files  Successfully\n",
      "Splitting documents...\n",
      "total docs to be stored:  0\n",
      "Storing database in directory 'db2'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m store \u001b[39m=\u001b[39m ingest(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                 \u001b[39m'\u001b[39;49m\u001b[39mdb_files\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                 file_types\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhtml, txt, pdf, docx, md, xml, json\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                 embeddings\u001b[39m=\u001b[39;49mOpenAIEmbeddings(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                         openai_api_key\u001b[39m=\u001b[39;49mopen_ai_api_key,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                         show_progress_bar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                     ),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                 persist_directory\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdb2\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                 persist\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m             )\n",
      "\u001b[1;32m/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb Cell 21\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m texts \u001b[39m=\u001b[39m process_docs(docs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m#store database\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m vector_store \u001b[39m=\u001b[39m store_db(texts, embeddings, persist_directory, persist)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mreturn\u001b[39;00m vector_store\n",
      "\u001b[1;32m/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb Cell 21\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m             time\u001b[39m.\u001b[39msleep(\u001b[39m90\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m     \u001b[39m#store texts\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m     vector_db \u001b[39m=\u001b[39m store([texts])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39mif\u001b[39;00m vector_db \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDatabase could not be stored\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mif\u001b[39;00m (persist \u001b[39mand\u001b[39;00m persist_directory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mor\u001b[39;00m (\u001b[39mnot\u001b[39;00m persist \u001b[39mand\u001b[39;00m persist_directory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m#store texts into directory\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStoring database in directory \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpersist_directory\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     vector_db \u001b[39m=\u001b[39m vector_store\u001b[39m.\u001b[39;49mfrom_documents(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m                                     documents\u001b[39m=\u001b[39;49mtext, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m                                     embedding\u001b[39m=\u001b[39;49membeddings,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m                                     persist_directory\u001b[39m=\u001b[39;49mpersist_directory\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m                                 )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m#else if persist is true and persist_directory is None\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39melif\u001b[39;00m persist \u001b[39mand\u001b[39;00m persist_directory \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/irfan/Documents/langchain_chatbot/chatbot_with_knowledge_base_chromadb.ipynb#X26sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39m#store texts into memory\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages/langchain/vectorstores/chroma.py:644\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    614\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_documents\u001b[39m(\n\u001b[1;32m    615\u001b[0m     \u001b[39mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    625\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Chroma:\n\u001b[1;32m    626\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create a Chroma vectorstore from a list of documents.\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \n\u001b[1;32m    628\u001b[0m \u001b[39m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[39m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m     texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    645\u001b[0m     metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    646\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_texts(\n\u001b[1;32m    647\u001b[0m         texts\u001b[39m=\u001b[39mtexts,\n\u001b[1;32m    648\u001b[0m         embedding\u001b[39m=\u001b[39membedding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    657\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages/langchain/vectorstores/chroma.py:644\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    614\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_documents\u001b[39m(\n\u001b[1;32m    615\u001b[0m     \u001b[39mcls\u001b[39m: Type[Chroma],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    625\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Chroma:\n\u001b[1;32m    626\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create a Chroma vectorstore from a list of documents.\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \n\u001b[1;32m    628\u001b[0m \u001b[39m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[39m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m     texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39;49mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    645\u001b[0m     metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    646\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_texts(\n\u001b[1;32m    647\u001b[0m         texts\u001b[39m=\u001b[39mtexts,\n\u001b[1;32m    648\u001b[0m         embedding\u001b[39m=\u001b[39membedding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    657\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "store = ingest(\n",
    "                'db_files',\n",
    "                file_types='html, txt, pdf, docx, md, xml, json',\n",
    "                embeddings=OpenAIEmbeddings(\n",
    "                                        openai_api_key=open_ai_api_key,\n",
    "                                        show_progress_bar=True\n",
    "                                    ),\n",
    "                persist_directory='db2',\n",
    "                persist=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Can use the following method in a .py script**\n",
    "\n",
    "It can also be run with in scheduled to automate directory loading and ingestion of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def main():\n",
    "#     parser = argparse.ArgumentParser(description='Ingest documents into a vector store')\n",
    "#     parser.add_argument('path', type=str, help='path of the dir to load documents from')\n",
    "#     parser.add_argument('file_types', type=str, help='file formats to load e.g. .pdf, .docx etc')\n",
    "#     parser.add_argument('persist_directory', type=str, help='directory to save the database')\n",
    "#     parser.add_argument('persist', type=bool, help='whether to persist the database or not')\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     #embeddings\n",
    "#     embeddings = OpenAIEmbeddings(openai_api_key=open_ai_api_key )\n",
    "\n",
    "#     #ingest documents\n",
    "#     store = ingest(args.path, args.file_types.strip(), embeddings, args.persist_directory, args.persist)\n",
    "\n",
    "#     print('Database stored successfully', store.get()['metadatas'][0]['source'])\n",
    "\n",
    "#     print('Exiting...')\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
