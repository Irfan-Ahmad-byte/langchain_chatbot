{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple implementation of AI chatbot with Langchain-OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.schema import AIMessage, SystemMessage, HumanMessage\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load .env file\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get open ai key and config\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the chat model\n",
    "\n",
    "chat_model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up chatbot and asking\n",
    "We define a system message for the chatbot and then a human message.\n",
    "\n",
    "- System message: tot ell the chatbot its role\n",
    "- human message: as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content='You are an expert American historian with immense knowledge about history of America.'),\n",
    "    HumanMessage(content='Who was the first president of America?'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask the chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The first president of America was George Washington. He served as the president from 1789 to 1797.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model(messages=messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first president of the United States was George Washington. He served as the president from 1789 to 1797. Washington was a key figure in the American Revolution and played a crucial role in the formation of the United States as a nation. He is often referred to as the \"Father of His Country\" due to his leadership and contributions to the early years of the United States.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = chat_model(messages=messages).content\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now the answer is stored in a variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see it it remembers our first question and replies accordingly (have memory)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'George Washington became the first president of the United States through a series of events and decisions made during the American Revolution and the establishment of a new government.\\n\\n1. Leadership during the Revolutionary War: Washington played a crucial role as the commander-in-chief of the Continental Army during the American Revolution. His military expertise, strategic decision-making, and ability to inspire and unite troops earned him respect and recognition among his peers and the public.\\n\\n2. Role in the Constitutional Convention: After the Revolutionary War, Washington attended the Constitutional Convention held in Philadelphia in 1787. His presence and support lent credibility to the proceedings, and he was unanimously elected as the president of the convention. His leadership helped shape the new U.S. Constitution, which established the framework for the federal government.\\n\\n3. Unanimous election as President: When the new Constitution was ratified and the United States was ready to elect its first president, Washington was widely regarded as the most suitable candidate due to his military leadership, integrity, and commitment to the principles of the Constitution. In 1788, he was unanimously elected by the Electoral College as the first president of the United States.\\n\\n4. Inauguration and establishment of the presidency: On April 30, 1789, Washington was inaugurated as the first president of the United States in New York City. He played a crucial role in establishing the precedents and norms of the presidency, including the two-term limit, respect for the office, and the exercise of executive authority.\\n\\nOverall, George Washington became the first president through his military leadership during the Revolutionary War, his active participation in the creation of the Constitution, and his widespread admiration and support among the American public and political leaders.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model(messages=[HumanMessage(content='How he became the first president?')]).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\'m sorry, but without context or information about who \"him\" refers to, I cannot provide an answer to your question. Could you please provide more details or clarify your question?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model(messages=[HumanMessage(content='Who became next president after him?')]).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First it answered accordingly, but now it does not recognize who I am talking about.\n",
    "\n",
    "Shall play with memory in another notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another approach to system role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {'name': 'system', 'content': 'You are a python expert with immense knowledge about python programming\\\n",
    "     and a teacher who can explain python concepts to anyone at any level of age or class.'},\n",
    "\n",
    "     {'name': 'human', 'content': 'I am a 5th grade student. Please explain me with an example\\\n",
    "      that what is a linked list?'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Got unknown type {'role': 'system', 'content': 'You are a python expert with immense knowledge about python programming     and a teacher who can explain python concepts to anyone at any level of age or class.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/irfan/Documents/my_projects/langchain_chatbot/langchain_chatbot.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/irfan/Documents/my_projects/langchain_chatbot/langchain_chatbot.ipynb#X45sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m chat_model(messages\u001b[39m=\u001b[39;49mmessages)\u001b[39m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages/langchain/chat_models/base.py:612\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    606\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    607\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    611\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessage:\n\u001b[0;32m--> 612\u001b[0m     generation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m    613\u001b[0m         [messages], stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    614\u001b[0m     )\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    615\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[1;32m    616\u001b[0m         \u001b[39mreturn\u001b[39;00m generation\u001b[39m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages/langchain/chat_models/base.py:365\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n\u001b[1;32m    364\u001b[0m             run_managers[i]\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 365\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    366\u001b[0m flattened_outputs \u001b[39m=\u001b[39m [\n\u001b[1;32m    367\u001b[0m     LLMResult(generations\u001b[39m=\u001b[39m[res\u001b[39m.\u001b[39mgenerations], llm_output\u001b[39m=\u001b[39mres\u001b[39m.\u001b[39mllm_output)\n\u001b[1;32m    368\u001b[0m     \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results\n\u001b[1;32m    369\u001b[0m ]\n\u001b[1;32m    370\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages/langchain/chat_models/base.py:355\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mfor\u001b[39;00m i, m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(messages):\n\u001b[1;32m    353\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m         results\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 355\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_with_cache(\n\u001b[1;32m    356\u001b[0m                 m,\n\u001b[1;32m    357\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    358\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[i] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    359\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    360\u001b[0m             )\n\u001b[1;32m    361\u001b[0m         )\n\u001b[1;32m    362\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    363\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages/langchain/chat_models/base.py:507\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    504\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    506\u001b[0m \u001b[39mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 507\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    508\u001b[0m         messages, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    509\u001b[0m     )\n\u001b[1;32m    510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(messages, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages/langchain/chat_models/openai.py:343\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m     stream_iter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream(\n\u001b[1;32m    340\u001b[0m         messages, stop\u001b[39m=\u001b[39mstop, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    341\u001b[0m     )\n\u001b[1;32m    342\u001b[0m     \u001b[39mreturn\u001b[39;00m _generate_from_stream(stream_iter)\n\u001b[0;32m--> 343\u001b[0m message_dicts, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_message_dicts(messages, stop)\n\u001b[1;32m    344\u001b[0m params \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}\n\u001b[1;32m    345\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompletion_with_retry(\n\u001b[1;32m    346\u001b[0m     messages\u001b[39m=\u001b[39mmessage_dicts, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    347\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages/langchain/chat_models/openai.py:358\u001b[0m, in \u001b[0;36mChatOpenAI._create_message_dicts\u001b[0;34m(self, messages, stop)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`stop` found in both the input and default params.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    357\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m stop\n\u001b[0;32m--> 358\u001b[0m message_dicts \u001b[39m=\u001b[39m [convert_message_to_dict(m) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages]\n\u001b[1;32m    359\u001b[0m \u001b[39mreturn\u001b[39;00m message_dicts, params\n",
      "File \u001b[0;32m~/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages/langchain/chat_models/openai.py:358\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`stop` found in both the input and default params.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    357\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m stop\n\u001b[0;32m--> 358\u001b[0m message_dicts \u001b[39m=\u001b[39m [convert_message_to_dict(m) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages]\n\u001b[1;32m    359\u001b[0m \u001b[39mreturn\u001b[39;00m message_dicts, params\n",
      "File \u001b[0;32m~/Documents/arabic_law_assistant/venv/lib/python3.9/site-packages/langchain/adapters/openai.py:84\u001b[0m, in \u001b[0;36mconvert_message_to_dict\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m     78\u001b[0m     message_dict \u001b[39m=\u001b[39m {\n\u001b[1;32m     79\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mfunction\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     80\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: message\u001b[39m.\u001b[39mcontent,\n\u001b[1;32m     81\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: message\u001b[39m.\u001b[39mname,\n\u001b[1;32m     82\u001b[0m     }\n\u001b[1;32m     83\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot unknown type \u001b[39m\u001b[39m{\u001b[39;00mmessage\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m message\u001b[39m.\u001b[39madditional_kwargs:\n\u001b[1;32m     86\u001b[0m     message_dict[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m message\u001b[39m.\u001b[39madditional_kwargs[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: Got unknown type {'role': 'system', 'content': 'You are a python expert with immense knowledge about python programming     and a teacher who can explain python concepts to anyone at any level of age or class.'}"
     ]
    }
   ],
   "source": [
    "chat_model(messages=messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
